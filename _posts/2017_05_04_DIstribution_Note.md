**Binomial Distribution**  
在概率论和统计学中，[二项分布](https://zh.wikipedia.org/wiki/%E4%BA%8C%E9%A0%85%E5%88%86%E4%BD%88)（英语：Binomial distribution）是n个独立的是/非试验中成功的次数的离散概率分布，
其中每次试验的成功概率为p。这样的单次成功/失败试验又称为伯努利试验(Bernoulli trial)。实际上，当n = 1时，二项分布就是伯努利分
布。二项分布是显著性差异的二项试验的基础。  

**chi-square distribution[2], χ²-distribution**  
[卡方分布](https://zh.wikipedia.org/wiki/%E5%8D%A1%E6%96%B9%E5%88%86%E4%BD%88)（chi-square distribution[2], χ²-distribution）是概率论与统计学中常用的一种概率分布。k个独立的标准正态分布变量的平方和服从自由度为k的卡方分布。卡方分布是一种特殊的伽玛分布，是统计推断中应用最为广泛的概率分布之一，例如假设检验和置信区间的计算。  

**Normal Distribution**   
[常態分佈](https://zh.wikipedia.org/wiki/%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83)（德语：Normalverteilung；英语：normal distribution）又名高斯分佈（德语：Gauß-Verteilung；英语：Gaussian distribution, 以德國數學家卡爾·弗裡德里希·高斯的姓冠名），是一個在數學、物理及工程等領域都非常重要的機率分佈，由于这个分布函数具有很多非常漂亮的性质，使得其在诸多涉及统计科学离散科学等领域的許多方面都有著重大的影響力。比如图像处理中最常用的滤波器类型为Gaussian滤波器（也就是所谓的正态分布函数）。
若隨機變量 {\displaystyle X} X服從一個位置參數為 {\displaystyle \mu } \mu 、尺度參數為 {\displaystyle \sigma } \sigma 的機率分佈，記為：
{\displaystyle X\sim N(\mu ,\sigma ^{2}),} X \sim N(\mu,\sigma^2),[1]
則其機率密度函數為
{\displaystyle f(x)={1 \over \sigma {\sqrt {2\pi }}}\,e^{-{(x-\mu )^{2} \over 2\sigma ^{2}}}} f(x) = {1 \over \sigma\sqrt{2\pi} }\,e^{- {{(x-\mu )^2 \over 2\sigma^2}}}[1]
常態分佈的數學期望值或期望值 {\displaystyle \mu } \mu 等於位置參數，決定了分佈的位置；其方差 {\displaystyle \sigma ^{2}} \sigma^2的開平方或標準差 {\displaystyle \sigma } \sigma 等於尺度參數，決定了分佈的幅度。
常態分佈的機率密度函數曲線呈鐘形，因此人們又經常稱之為鐘形曲線。我們通常所說的標準常態分佈是位置參數 {\displaystyle \mu =0} \mu =0，尺度參數 {\displaystyle \sigma ^{2}=1} \sigma^2 = 1的常態分佈[1]（見右圖中綠色曲線）。  

**Variance**  
[方差](https://zh.wikipedia.org/wiki/%E6%96%B9%E5%B7%AE)（Variance），應用數學裡的專有名詞。在概率论和统计学中，一个随机变量的方差描述的是它的离散程度，也就是该变量离其期望值的距离。一个实随机变量的方差也称为它的二阶矩或二階中心動差，恰巧也是它的二阶累积量。這裡把複雜說白了，就是將各個誤差將之平方（而非取絕對值），使之肯定為正數，相加之後再除以總數，透過這樣的方式來算出各個數據分佈、零散（相對中心點）的程度。繼續延伸的話，方差的算术平方根称为该随机变量的标准差（此為相對個體間）。  The average of the squared differences from the Mean.   
设X为服从分布F的随机变量， 如果E[X]是隨機變數X的期望值（平均數μ=E[X]）
随机变量X或者分布F的方差為：
{\displaystyle \operatorname {Var} (X)=\operatorname {E} \left[(X-\mu )^{2}\right]} \operatorname{Var}(X) = \operatorname{E}\left[(X - \mu)^2 \right]  

**Standard Deviation**  
[The Standard Deviation](http://www.mathsisfun.com/data/standard-deviation.html) is a measure of how spread out numbers are.
The formula is easy: it is the square root of the Variance.   
Its symbol is σ (the greek letter sigma)   

**Gamma Distribution**   
\Gamma \,函数，也叫做伽瑪函數（Gamma函数），是階乘函數在實數與複數上的擴展。對於實數部份為正的複數 {\displaystyle z} z，伽瑪函數定義為：
{\displaystyle \Gamma (z)=\int _{0}^{\infty }{\frac {t^{z-1}}{\mathrm {e} ^{t}}}\,{\rm {d}}t}  \Gamma(z) = \int_{0}^{\infty} \frac{t^{z-1}}{\mathrm{e}^t} \,{\rm{d}}t
此定義可以用解析開拓原理拓展到整個複數域上，非正整數除外。
如果 {\displaystyle n} n為正整數，則伽瑪函數定義為：
{\displaystyle \Gamma (n)=(n-1)!}  \Gamma(n) = (n-1)!，
這顯示了它與階乘函數的聯繫。可見，伽瑪函數將 {\displaystyle n!} n!拓展到了實數與複數域上。
在概率論中常見此函數，在組合數學中也常見。

**Bimodal Distribution**  
Data distributions in statistics can have one peak, or they can have several peaks. The type of distribution you might be familiar with seeing is the normal distribution, or bell curve, which has one peak. The bimodal distribution has two peaks.  
[graph](http://www.statisticshowto.com/wp-content/uploads/2013/07/Bimodal.png)  
The “bi” in [bimodal distribution](http://www.statisticshowto.com/what-is-a-bimodal-distribution/) refers to “two” and modal refers to the peaks. It can seem a little confusing because in statistics, the term “mode” refers to the most common number. However, if you think about it, the peaks in any distribution are the most common number(s). The two peaks in a bimodal distribution also represent two local maximums; these are points where the data points stop increasing and start decreasing.  

**Explanation of density**  	
The results estimate points per unit area. As a check, you should multiply the density values by the area of a cell and add up these values over the grid: the total should equal the sum of the original data. (These two values often differ for two reasons, boundary effects and numerical imprecision. The boundary effects occur because the density map can spread data off the edge of the map and those values don't get recovered from the density grid. But the differences ought to be small.)

One image I have used in classes asks students to imagine the kernel as a bucket of sand: you upend the bucket at a point, allowing the sand to slump. The slumping barely occurs for short half-widths but is extensive for large band-widths (maybe the sand is wetter ;-). Regardless, it's always the same amount of sand left, no matter how slumping occurs. Now go dump one bucket at the location of each point (or, more generally, if there is a positive value x associated with each data point, first put an amount of sand in the bucket proportional to x and then dump it). The sand slumps. It piles up in areas where there are lots of buckets. The density grid gives you the height of the piled sand at the center of each grid cell. Multiplying this by a cell's area estimates the volume of sand occupying each cell. Summing this cell volume over any region (such as a Census block) estimates the total volume of sand in that region, which represents the total amount of quantity x you think is in the region.


[Empirical Cumulative Distribution Functio and CDF](https://stats.stackexchange.com/questions/239937/empirical-cdf-vs-cdf)
