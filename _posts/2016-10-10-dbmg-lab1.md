---
layout: post
title:  Database Management Systems Practice #1 â€“ Oracle Optimizer 
categories: [blog ]
tags: [study,database,oracle,optmizer ]
description: Generate the execution plan for some SQL statements analyzing the following issues: 
1.access paths 2.join orders and join methods 3.operation orders 4.exploitation of indexes defined
by the user. The evaluation will be performed using Oracle Database 10g Express Edition (Oracle XE).
---  
**How the Query Optimizer Chooses an Access Path**
The query optimizer chooses an access path based on the following factors:

The available access paths for the statement
The estimated cost of executing the statement, using each access path or combination of paths
To choose an access path, the optimizer first determines which access paths are available by examining the conditions in the statement's WHERE clause and its FROM clause. The optimizer then generates a set of possible execution plans using available access paths and estimates the cost of each plan, using the statistics for the index, columns, and tables accessible to the statement. Finally, the optimizer chooses the execution plan with the lowest estimated cost.

When choosing an access path, the query optimizer is influenced by the following:

Optimizer Hints

The optimizer's choice among available access paths can be overridden with hints, except when the statement's FROM clause contains SAMPLE or SAMPLE BLOCK.

Old Statistics

For example, if a table has not been analyzed since it was created, and if it has less than DB_FILE_MULTIBLOCK_READ_COUNT blocks under the high water mark, then the optimizer thinks that the table is small and uses a full table scan. Review the LAST_ANALYZED and BLOCKS columns in the ALL_TABLES table to examine the statistics.

**Setting up the optimizer environment**
 At the beginning of working session you need to perform the following steps:
 1.compute statistics on tables by means of the Web Interface or by the following script comp_statistics_tables.sql

Query optimization with statistics uses the collected statistics on the tables and indexes in a query to select an execution plan that
can process the query in the most efficient manner. The optimizer attempts to choose the best execution plan based on the following
parameters:

the selectivity on the CONTAINS predicate
the selectivity of other predicates in the query
the CPU and I/O costs of processing the CONTAINS predicates
#### Collecting Statistics
By default, the extensible query optimizer is enabled. To use the extensible optimizer, you must calculate the statistics on the table 
you query. To do so, issue the following statement:
`ANALYZE TABLE <table_name> COMPUTE STATISTICS; `
 2.check if there exist secondary indexes by means of the following SQL query select INDEX_NAME from USER_INDEXES;
 if  secondary  indexes  (without  considering  system  indexes,  e.g.,  SYS_#)  have  been  created, please, drop
 them by means of the following SQL statement DROP INDEX IndexName;
 
###### Query1
Change  the  optimizer  goal  from  ALL  ROWS  (best  throughput) to  FIRST_ROWS  (best  response time)

**First_rows** attempts to optimize the query to get the very first row back to the client as fast as possible. This is good for an interactive client server environment where the client runs a query and shows the user the first 10 rows or so and waits for them to page down to get more.

**All_rows** attempts to optimize the query to get the very last row as fast as possible. This makes sense in a stored procedure for example where the client does not regain control until the stored procedure completes. You don't care if you have to wait to get the first row if the last row gets back to you twice as fast. In a client server/interactive application you may well care about that.
[reference](http://myorastuff.blogspot.it/2008/09/optimizer-mode-firstrows-vs-allrows.html "reference")
- 1a
![](http://i.imgur.com/8nJwsSJ.png)
**Full Table Scans**
This type of scan reads all rows from a table and filters out those that do not meet the selection criteria. During a full table scan, all blocks in the table that are under the high water mark are scanned. The high water mark indicates the amount of used space, or space that had been formatted to receive data. Each row is examined to determine whether it satisfies the statement's WHERE clause.

When Oracle performs a full table scan, the blocks are read sequentially. Because the blocks are adjacent, I/O calls larger than a single block can be used to speed up the process. The size of the read calls range from one block to the number of blocks indicated by the initialization parameter DB_FILE_MULTIBLOCK_READ_COUNT. Using multiblock reads means a full table scan can be performed very efficiently. Each block is read only once.
For details, see [[1]][1]

**Hash joins** are used for joining large data sets. The optimizer uses the smaller of two tables or data sources to build a hash table on the join key in memory. It then scans the larger table, probing the hash table to find the joined rows.

This method is best used when the smaller table fits in available memory. The cost is then limited to a single read pass over the data for the two tables.
**When the Optimizer Uses Hash Joins**

The optimizer uses a hash join to join two tables if they are joined using an equijoin and if either of the following conditions are true:

A large amount of data needs to be joined.
A large fraction of a small table needs to be joined.

- 1b
[![](http://i.imgur.com/S7kYgvW.png)
**Nested loop joins** are useful when small subsets of data are being joined and if the join condition is an efficient way of accessing the second table. <10^3
A nested loops join is particularly effective if the outer input is small and the inner input is preindexed and large. In many small transactions, such as those affecting only a small set of rows, index nested loops joins are superior to both merge joins and hash joins. In large queries, however, nested loops joins are often not the optimal choice.

http://imgur.com/a/yILxR
Changing the optimizer goal to /*+ FIRST_ROWS(1) */ (n=1) the optimizer prefers to use nested loop (with  DEPT  as  inner  table  and  EMP  as  outer  table).  The  inner  table  is  accessed  using  unique  index scan, which exploits the index on the primary key. Increasing the value of n from 1 to 3 (or more) the optimizer chooses the same plan as in best throughout configuration (hash join and table access full for both tables). 

Query2
The NO_USE_HASH hint instructs the optimizer to exclude hash joins when joining each specified table to another row source using the specified table as the inner table. For example:
http://imgur.com/GtI28hC
Since the hint is to avoid hash, the Oracle optimizer prefers a Nested loop (performing a FULL TABLE ACCESS on the table EMP and creating a view of the table resulting from the group by). Table DEPT is accessed by using a UNIQUE SCAN on the primary key.

USE_HASH
http://imgur.com/L8CJz6s

QUERY3
NO_USE_HASH
http://imgur.com/G3mvCWg
USE_HASH
http://imgur.com/lFS07Cz

Using Histograms to Help Oracle Cost-Based Optimizer Make Better Decisions
http://logicalread.solarwinds.com/using-histograms-to-help-oracle-cost-based-optimizer-make-better-decisions-dr01/#.WAdtX_myNBc
 Oracle is assuming uniform data distribution in the column skew values and estimating the
cardinality = density * 10000 = 909.09 rows. However we know that we have only one row with
skew=1 and 9990 rows with skew=10000. This assumption is bound to result in sub-optimal
execution plan. For example, if we have an index on column skew, Oracle will use it for the predicate
skew=10000 considering the number of rows to be returned equals to 909 or only 9.09%. 

Once histogram is created for a column, it tells the CBO the frequency of a column value. So in our
case it would tell the optimizer that we have 1 occurrence (frequency) of skew=1 and 9990 of
skew=10000. Thus it will enable the optimizer to choose better execution plans. 
https://neerajbhatia.files.wordpress.com/2010/11/everything-you-want-to-know-about-oracle-histograms-part-1.pdf


Query4
without index
http://imgur.com/gniWAZQ
After  creating  an  index  on  attribute  Sal  of  Table  EMP  (create  index  EmpSalInd  ON  EMP(sal);)  and another index on attribute Deptno of Table EMP (create index DeptnoInd ON EMP(deptno);), the two indexes are used separately (index range scan) to perform selection operations on different attributes.

The selectivity of an index is the percentage of rows in a table having the same value for the indexed column.
